// This file was generated by lezer-generator. You probably shouldn't edit it.
import { LRParser } from '@lezer/lr';
export const parser = LRParser.deserialize({
  version: 14,
  states:
    "$bOQOPOOOVOPO'#C^QbOPOOOgOQO,58xOoOPO,58xOtOSO,58xOyOWO'#CeQbOPOOOOOO1G.d1G.dO!OOQO1G.dO!TOQO1G.dO!]OPO1G.dOOOO,59P,59POOOO-E6c-E6cOOOO7+$O7+$OO!bOQO7+$OO!gOPO7+$OOOOO<<Gj<<GjO!oOQO<<GjO!wOPO<<GjOOOOAN=UAN=UO!|OQOAN=UO#ROQOAN=UOOOOG22pG22pO#ZOQOG22pOOOOLD([LD([",
  stateData:
    '#`~ORPO~OZTO]SO^RO~OVUO~OTXOUWO~O^YO~OSZO~OW[O~OU^O~OT_OU^O~O[`O~OUaO~O]cO^bO~OTeOUdO~O^fO~OUgO~OThOUgO~OUiO~O',
  goto: 'dYPPZPPPPPP^RQOQVQR]V',
  nodeNames:
    'âš  Program Summary Type Scope Whitespace Description NewLines Body',
  maxTerm: 14,
  skippedNodes: [0],
  repeatNodeCount: 1,
  tokenData:
    '$r~RbXY!ZYZ#OZ^!Zpq!Zqr#{xy$Qyz$V![!]$[!c!}$a#T#o$a#y#z!Z$f$g!Z#BY#BZ!Z$IS$I_!Z$I|$JO!Z$JT$JU!Z$KV$KW!Z&FU&FV!ZQ!`YTQX^!Zpq!Z#y#z!Z$f$g!Z#BY#BZ!Z$IS$I_!Z$I|$JO!Z$JT$JU!Z$KV$KW!Z&FU&FV!ZR#V[VPTQXY!ZYZ#OZ^!Zpq!Z#y#z!Z$f$g!Z#BY#BZ!Z$IS$I_!Z$I|$JO!Z$JT$JU!Z$KV$KW!Z&FU&FV!Z~$QO]~~$VOZ~~$[O[~~$aO^~_$lQWWUQSSRP!c!}$a#T#o$a',
  tokenizers: [0, 1, 2, 3],
  topRules: { Program: [0, 1] },
  tokenPrec: 0,
});
